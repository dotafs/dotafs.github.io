<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>games101_笔记(光追)</title>
    <link href="/2022/08/12/games101-%E7%AC%94%E8%AE%B0-%E5%85%89%E8%BF%BD/"/>
    <url>/2022/08/12/games101-%E7%AC%94%E8%AE%B0-%E5%85%89%E8%BF%BD/</url>
    
    <content type="html"><![CDATA[<h2 id="intro-："><a href="#intro-：" class="headerlink" title="intro ："></a>intro ：</h2><p>因为光栅化(rasterization)没法做到很真实的物理效果，所以我们尝试使用光线追踪(ray tracing)， 因为光追会显现出来更加真实的物理效果，反之会消耗更多的时间去渲染。</p><h2 id="step-1-light-rays-："><a href="#step-1-light-rays-：" class="headerlink" title="step 1 (light rays)："></a>step 1 (light rays)：</h2><p>尽管光追能做到拟真是世界光源，但光线追踪和物理上光的反射不太一样，在cg中我们这么定义：</p><ol><li>光沿直线传播</li><li>光线相交互不影响</li><li>光路可逆，光线传入眼睛可以当作眼睛发出光线。</li></ol><center><img src="/2022/08/12/games101-%E7%AC%94%E8%AE%B0-%E5%85%89%E8%BF%BD/1.jpeg" alt="GAM GLM ..." width="1300" height="150"> <br>GAM GLM ...</center><h2 id="step-2（pinhole-camera-model"><a href="#step-2（pinhole-camera-model" class="headerlink" title="step 2（pinhole camera model):"></a>step 2（pinhole camera model):</h2>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>关于NeuralTalk2</title>
    <link href="/2022/07/17/%E5%85%B3%E4%BA%8ENeuralTalk2/"/>
    <url>/2022/07/17/%E5%85%B3%E4%BA%8ENeuralTalk2/</url>
    
    <content type="html"><![CDATA[<h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><p>参考的步骤进行配置</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/karpathy/</span>neuraltalk2<span class="hljs-regexp">/tree/</span><span class="hljs-number">3</span>c81602809b8b9e5bd3e9e213bf955986485dda7\<br></code></pre></td></tr></table></figure><p>我的环境是macOS + M1</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">$ curl -s https://raw.githubusercontent.com/torch/ezinstall/master/install-deps | bash<br>$ git clone https://github.com/torch/distro.git ~/torch --recursive<br>$ cd ~/torch; <br>$ ./install.sh      # and enter &quot;yes&quot; at the end to modify your bashrc<br>$ source ~/.bashrc <br></code></pre></td></tr></table></figure><p>接下来</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">$ luarocks install nn<br>$ luarocks install nngraph <br>$ luarocks install image <br></code></pre></td></tr></table></figure><p>在上面进行luarock安装的时候报错</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs awk">Installing https:<span class="hljs-regexp">//</span>raw.githubusercontent.com<span class="hljs-regexp">/torch/</span>rocks<span class="hljs-regexp">/master/</span>nn-scm-<span class="hljs-number">1</span>.rockspec...<br>Using https:<span class="hljs-regexp">//</span>raw.githubusercontent.com<span class="hljs-regexp">/torch/</span>rocks<span class="hljs-regexp">/master/</span>nn-scm-<span class="hljs-number">1</span>.rockspec... switching to <span class="hljs-string">&#x27;build&#x27;</span> mode<br>正克隆到 <span class="hljs-string">&#x27;nn&#x27;</span>...<br>fatal: 无法连接到 github.com：<br>github.com[<span class="hljs-number">0</span>: <span class="hljs-number">140.82</span>.<span class="hljs-number">121.4</span>]: errno=Operation timed out<br></code></pre></td></tr></table></figure><p>我的解决方案有两个步骤</p><ol><li>(我觉得这个问题和这个步骤没关系) 我首先安装了lua</li></ol><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-variable">$</span> <span class="hljs-built_in">curl</span> <span class="hljs-literal">-R</span> <span class="hljs-literal">-O</span> http://www.lua.org/ftp/lua<span class="hljs-literal">-5</span>.<span class="hljs-number">4.3</span>.tar.gz<br><span class="hljs-variable">$</span> tar <span class="hljs-literal">-zxvf</span> lua<span class="hljs-literal">-5</span>.<span class="hljs-number">4.3</span>.tar.gz<br><span class="hljs-variable">$</span> <span class="hljs-built_in">cd</span> lua<span class="hljs-literal">-5</span>.<span class="hljs-number">4.3</span><br><span class="hljs-variable">$</span> make<br></code></pre></td></tr></table></figure><ol start="2"><li>还是stackoverflow好用（不是 ，加这个命令行就好了。</li></ol><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">git config --global url.https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/.insteadOf git:/</span><span class="hljs-regexp">/github.com/</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>openGL学习笔记(1)</title>
    <link href="/2022/07/08/openGL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/"/>
    <url>/2022/07/08/openGL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/</url>
    
    <content type="html"><![CDATA[<h1 id="“GLShaderManager-h”-和-“GLTools-h”"><a href="#“GLShaderManager-h”-和-“GLTools-h”" class="headerlink" title="“GLShaderManager.h” 和 “GLTools.h”"></a>“GLShaderManager.h” 和 “GLTools.h”</h1>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>openGL的学习笔记</title>
    <link href="/2022/07/02/openGL%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2022/07/02/openGL%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>模型的透明度</title>
    <link href="/2022/06/24/%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%8F%E6%98%8E%E5%BA%A6/"/>
    <url>/2022/06/24/%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%8F%E6%98%8E%E5%BA%A6/</url>
    
    <content type="html"><![CDATA[<h1 id="explainable-AI-（XAI）"><a href="#explainable-AI-（XAI）" class="headerlink" title="explainable AI （XAI）"></a>explainable AI （XAI）</h1><h3 id="XAI"><a href="#XAI" class="headerlink" title="XAI"></a>XAI</h3><p>指的是让人们明白这个模型是为什么得到这个结果的。因为AI有可能会作弊。比如通过看图片是否有copyright里面是不是有马的字段来判断图片是不是马。</p><p>XAI 我们就可以不断的人为优化模型。</p><p>black-box AI， 与XAI相反。 我们不知道模型通过什么得到的结果也不知道如何优化。</p><h3 id="各种learning"><a href="#各种learning" class="headerlink" title="各种learning"></a>各种learning</h3><p>监督学习(supervised learning):<br>  每个数据都有对应的label。良性肿瘤和恶性肿瘤。</p><p>无监督学习(unsupervised learning):<br>  数据没有labels。我们不知道每一个数据对应的什么意思。比如google有上千个新闻。我们没发给每一个加上label。我们就可以通过”聚类”的形式来将相似的定为一个专栏，达成新闻分类。</p><p>表示学习(representation learning):<br>  不同方法来表示学习。比如hsv和rgb都可以表示颜色。</p><center><img src="/2022/06/24/%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%8F%E6%98%8E%E5%BA%A6/1.jpeg" alt="各种学习的精准度和可解释度" width="256" height="256"> <br>各种学习的精准度和可解释度</center><h3 id="各种model"><a href="#各种model" class="headerlink" title="各种model"></a>各种model</h3><h4 id="Interpretable-Models"><a href="#Interpretable-Models" class="headerlink" title="Interpretable Models"></a>Interpretable Models</h4><p>• Decision Trees, Lists a ,Sets and rules <br>基本的if else</p><p>• GAMs <br>• GLMs <br>• Linear regression <br>• Logistic regression \</p><center><img src="/2022/06/24/%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%8F%E6%98%8E%E5%BA%A6/2.jpeg" alt="GAM GLM ..." width="1300" height="150"> <br>GAM GLM ...</center><p>• KNNs</p><h3 id="End-to-End-XAI"><a href="#End-to-End-XAI" class="headerlink" title="End-to-End XAI"></a>End-to-End XAI</h3><p>比传统的represtation learning 多了更多的不同等级的特征。 比如：<br>simple feature -&gt; complex feature -&gt; more complex feature。<br>这种结构对模型参数的调节空间更大。</p><h3 id="Shapley-Additive-Explanation"><a href="#Shapley-Additive-Explanation" class="headerlink" title="Shapley Additive Explanation"></a>Shapley Additive Explanation</h3>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>BIG-bench</title>
    <link href="/2022/06/24/BIG-bench/"/>
    <url>/2022/06/24/BIG-bench/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
    <tags>
      
      <tag>我的笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>学习如何使用openai</title>
    <link href="/2022/06/21/%E5%AD%A6%E4%B9%A0%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8openai/"/>
    <url>/2022/06/21/%E5%AD%A6%E4%B9%A0%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8openai/</url>
    
    <content type="html"><![CDATA[<h3 id="text-davinci-002"><a href="#text-davinci-002" class="headerlink" title="text-davinci-002"></a>text-davinci-002</h3>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>never ending learning 笔记</title>
    <link href="/2022/06/07/never_ending_learning/"/>
    <url>/2022/06/07/never_ending_learning/</url>
    
    <content type="html"><![CDATA[<p> NELL 早期采用 Carlson et al. 模型。它的作用是阅读Web来获取信息。<br><p>输入：<br></p><ol><li>一个初始的 ontology 里面存放着很多categories （运动，运动员）。一个二原组的realtion 表示着 categories之间的关系。 比如：  哪个运动员在玩什么运动（x,y）。<br></li><li>每一个relation 或者是 categories 都有差不多12个labels， 比如运动有足球篮球一类的名词。<br></li><li>Web 从ClueWeb（一个有着1亿个网页的数据集）中获得。并且Google授权了NELL 10万个搜索问题的api。<br></li><li>偶尔会有人为参与。<br></li></ol><p>做什么：<br></p><ol><li>抓去更多的信息从web 并且移除老的不正确的信息。在这个过程中数据集不断的增长并且每一个information都有着出处和可信度。</li><li>每天学习如何比昨天读得更好</li></ol><p>总体来讲，NELL软件层面上的架构是：beliefs通过NEIL，OntExt 等一些辨别手段来选出一些候选的beliefs 再通过knowledge integrator 来对原有的beliefs 进行更新。</p><p>期望最大化算法（EM）:在概率模型中寻找最大似然<br><br>似然 (likelihood):对于模型的不同参数出现目标样本的概率是多少<br><br>知识整合 (Knowledge Integration): 就是将多个知识模型转化为一个公用的模型。像是通过多种角度判断一个游戏的好坏，比如画面模型，剧情模型。 将这些模型整合起来来得到一个评判游戏的好坏程度的模型。</p><p>NELL 的学习过程类似于EM用于半监督学习。每一次循环都有E-like step 和 M-like step。<br></p><ol><li>E-like step : 所有的beliefs 都需要重新被估计。在NELL中的每一个reading和inference 模型 都需要更新到KB之中（曾加或者减少一些beliefs）。通过知识整合（KI）我们将一大堆独立的建议转化为对每一个潜在kb 里面的 belief 的可信度。<br></li><li>M-like step :对上面更新的每一个模型都做一个针对于他们的学习算法。得到了一个上千个互相关联的学习任务。<br></li></ol><p>NELL因为做不到完全EM算法。所以我们在进行E-like的时候设置一个upperbound。那些有高可信度的新的belief才会被我们考虑并更新到KB之中。<br>并且当我们更新的时候，采用limited-radius fashion的方式。简单来说就是我们只考虑当前更新的belief直接相关的beliefs的更新，不再做进一步的考虑。</p><h2 id="Knowledge-Integrator"><a href="#Knowledge-Integrator" class="headerlink" title="Knowledge Integrator"></a>Knowledge Integrator</h2><p>KI只考虑类别类型一致的beliefs。比如他只检验在relation triple中的实体类型是不是与realtion一致。而不是考虑用一个新的triple作为一个触发器来更新beliefs在同一次循环之中。</p><h2 id="新增学习任务和实体"><a href="#新增学习任务和实体" class="headerlink" title="新增学习任务和实体"></a>新增学习任务和实体</h2><h3 id="OntExt"><a href="#OntExt" class="headerlink" title="OntExt"></a>OntExt</h3><p>OntExt 创建新realtion。他通过寻找像所有已经有的实体，去寻找那个最新最经常被考虑的relation，把他用于链接两个实体。实现这个过程分为三步：</p><ol><li>一个句子中如果有已经存在的category pair了。就将它直接提取出。像是&lt;动物，食物&gt;。狗在吃肉。 狗和肉就被提取出来了。</li><li>把一个文章构建出一个2D矩阵用来寻找新的relation。</li><li>OntExt自动发现新的relations。发现了之后立刻做为一个触发器用来适应于新的句子。</li></ol><h3 id="VerbKB"><a href="#VerbKB" class="headerlink" title="VerbKB"></a>VerbKB</h3><p>动词和动词短语经常用于表达名词之间的关系。有点像是一个动词的模式，用来分析主语，宾语还有动词短语之间的关系。作为一个三元组。&lt;主语category，动词短语，宾语category&gt;。NELL已经有6.5w个动词了。覆盖了ClueWeb2010的98%。现在正在寻找扩大这个动词规模的方法。</p><h3 id="关于自我评估和自我反思"><a href="#关于自我评估和自我反思" class="headerlink" title="关于自我评估和自我反思"></a>关于自我评估和自我反思</h3><p>期望NELL可以针对于他应该着重学习的地方进行学习而不是像现在这样只会检测没有。目前的研究目标就是把未标记的数据用作数据集。我们可以这么来做：通过Platanios et al.32我们知道如果我们有三个或者更多的funciton用来求解。我们判断是否所有的函数得到的都是同一个名词，因为他们判断成功与否是独立的。所以可以通过他们的精准度来判断模型的好坏。通过这种方式精准度在逐年增加。<br>NELL对于不同种类的词语表现相差很多。比如对河流，身体部分这种精准度能到95% 但是对于国家的首都精准度就很低。原因有两种：</p><ol><li>有可能我们的目标得到的结果并不在我们想要的集合里面，我们就给他新定义一个集合。可能这个集合只能被他自己所用，并且会误导别的我们想要测试的目标的正确性。</li><li>可能NELL已经弄错了，由于错误的传播谓语。就比如我们目前的NELL他判定所有的星球名字都以什么什么球为结尾。如果我们拿出来一个不是以球结尾的他就没法正确判断了。</li></ol><p>有一些很简单的词汇被复杂化了。比如开心 -&gt; 难以置信的开心。这使得学习任务变得越来越多。未来的研究就是让他有自我反思的能力。</p><h2 id="汇总"><a href="#汇总" class="headerlink" title="汇总"></a>汇总</h2><p>NELL 作为一个早期的案例有很多我们吸取教训的地方：</p><ol><li>coupling constraints限制了后续学习其他任务。</li><li>允许去学习新的coupling constraints。</li><li>现阶段模型是a-b c-d ， a-b-c-d是一个全新的模型。未来需要做到的是把a-b 作为一个谓词短语 来使用。 已达成（a-b）- (c-d)的目的。</li></ol><p>NELL的限制：</p><ol><li>没有反思。他不会意识到自己做错了很久且没有任何进展。也没有监控自己性能的能力。</li><li>有些方法是固定的。可塑性很差。比如寻找名词或者名词短语这种方法。我们是无法进行学习或者更改的。</li><li>目前NELL只用了一个简单的frame base。 他没有框架去推到时间和空间。</p></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>我的笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
